<!DOCTYPE html>
<html>
  <head>
    <title>Topic</title>
    <link rel="stylesheet" href="minimal-table.css" />
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100..900;1,100..900&display=swap" rel="stylesheet">
  </head>

  <body>
<div id="circle"></div>
    <!-- Site navigation menu -->
  <ul class="navbar">
    <li><a href="index.html">Home</a></li>
    <li><a href="topic.html">Topic</a></li>
    <li><a href="opportunities.html">Opportunities</a></li>
    <li><a href="risks.html">Risks</a></li>
    <li><a href="choices.html">Choices</a></li>
    <!--<li><a href="ethics.html">Ethical Reflections</a></li>-->
    <li><a href="references.html">References</a></li>
    <li><a href="process.html">Process Support</a></li>
  </ul>

    <!-- Main content -->
       <div class="content">
      <div class="group"><p>G:4</p></div> 
    
    
    <h1>Between Free Speech and Control: Twitter/X's Moderation Crisis</h1>
<hr>

<h2>
  Introduction
         </h2>
         
    <p>
      In the focus of human rights, free speech remains a controversial
      topic — defined as “...the right to freedom of expression… either orally, in
      writing or in print, in the form of art, or through any other media of his
      choice.” (United Nations, 1966)
      However, we see changes in our digital age. Social media platforms now
      play a large role in shaping public speech. No longer just communication
      tools among some internet users, they now decide what is seen and what goes
      unseen. 
      <br><br>
          <h2>
      The Impact of Inconsistent Content Moderation on User Trust and Public Discourse on Twitter/X:
    </h2>
      A great example is “Twitter.” Under Elon Musk’s ownership, it has
      changed significantly. What was once a safe space for open discussion is
      now controlled by one person, with moderation rules that seem to change
      depending on the owner's convenience. A key example was when X
      started suspending multiple journalists' accounts who reported on Musk’s
      private jet in late 2022 and opposed him for not following his promises (O’Brien, 2022).
    </p>

 <div class="text-image-row">
  <div class="text-left">
    <p>
      Today, 63.9% of the population uses social media, with 2 hours and 21
      minutes being the average daily usage (Chaffey, 2025). Our lives are
      now centred around social media. Additionally, we share our words just
      as we do offline, but for <em>millions</em> globally to see. Hence why
      it is extremely important to protect users online, whether it be for
      their safety or others. This is where content moderation becomes
      increasingly important for the safety of users. Another important
      consideration is the online personas we are forming and if they truly
      represent us, or if our accounts and profiles are doing more harm than
      good. The words we post online shape this persona. In fact, an older
      study showed that 64% of teens made new friends through social media and
      felt more connected with each other’s lives and feelings (Lenhart, 2015).
      This percentage has likely grown exponentially over the
      years; imagine how many connections people are making on social media today.  
      <br><br/>
      The social and psychological implications of general online speech are
      extensive (Tao &amp Fisher, 2022). When individuals are silenced or misrepresented due to biased
      algorithms or inconsistent moderation practices, it not only impacts their
      digital identity but even their mental well-being (CCDH, 2023). People see social media
      as not just a means to communicate, but also a way to seek validation from
      peers (Lenhart, 2015), share ideas, and participate in discourse. If users' voices are
      unfairly suppressed, they may lose trust in the platform, feel socially
      isolated, and ultimately leave the platform (CCDH, 2023). This is what we see in X. With
      X being frequently used, we can see where inappropriate content moderation
      can become a large issue.
      <br/><br/>
      Figure 1 shows just how active users on X are, with the average 'Tweets' per week being 2.16 (Mundaden, 2025).
    </p>

    <p>
      X has the ability to connect people around the world and form
      online communities, providing a place for discourse and for people to
      share their thoughts and knowledge on anything they want. However, this
      openness must be protected by policies that are transparent and fair (CCDH, 2023).
      Without fair and transparent policies, not only is there a risk of
      censorship being taken too far, but also the deterioration of user-trust
      for their platform that claims to advocate for free expression.
      This information, together, highlights the importance of protecting and portraying our
      true selves online, especially on a platform like X. However, by getting
      misrepresented based on biased moderation, not only are our personalities
      stripped, but ultimately, our freedom is too.
      <br/><br/>
      This is the grey area of content moderation on X, which creates ethical
      dilemmas that are important to think about, especially as consumers of X.
    </p>
  </div>
     
  <div class="figures">
    <img src="https://cdn.glitch.global/5556ebdb-685a-4d04-aa89-e5756f7b1ce6/twitteractivity.png?v=1748236333234" 
         alt="Median tweets per week across all industries is 2.16" />
    <p>(Figure 1. Twitter Activity via Mundaden, 2025)</p>
  </div>
</div>

  <hr> 
         
      <address>
        Made May 2025<br />
        by Group 4: Sameer Farhan, Kevin Sabdao, Archy Prajapati.
      </address>
    </div>
  </body>
</html>
