<!DOCTYPE html>
<html>
  <head>
    <title>Home</title>
    <link rel="stylesheet" href="minimal-table.css" />
    
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100..900;1,100..900&display=swap" rel="stylesheet">
  </head>

  <body>
    <div id="circle"></div>
    <!-- Site navigation menu -->
    <ul class="navbar">
      <li><a href="index.html">Home</a></li>
      <li><a href="topic.html">Topic</a></li>
      <li><a href="opportunities.html">Opportunities</a></li>
      <li><a href="risks.html">Risks</a></li>
      <li><a href="choices.html">Choices</a></li>
      <!--<li><a href="ethics.html">Ethical Reflections</a></li>-->
      <li><a href="references.html">References</a></li>
      <li><a href="process.html">Process Support</a></li>
    </ul>

    <!-- Main content -->
    <div class="content">
      <div class="group"><p>G:4</p></div>

      <h1>Between Free Speech and Control: X’s Moderation Crisis</h1>
      <hr />

<div class="text-image-row">
  <div class="text-left">
    <p>
      <h2>Abstract</h2>
      Twitter, rebranded as X under Elon Musk’s ownership, has faced <em>continuous</em>
      controversies regarding the <em>inconsistency and transparency of its content
      moderation practices</em>, which has raised substantial concerns about the platform’s
      role in <em>upholding</em> or <em>threatening</em> the principles of free speech; a
      pillar of human rights found in many societies. Principles that are <i>fundamental</i>
      to the human experience. Upholding free speech is a responsibility that falls on the
      shoulders of <em>all</em> social media platforms; Facebook, Instagram, Youtube, and
      others alike. Whether they follow this, is up to the consumer's opinions. While freedom
      of expression must be protected, it must also be balanced with the responsibility to
      ensure user safety by removing harmful, hateful, explicit, or violent content. This
      delicate balance is the challenge all major social media platforms face. However, 
      unfortunately, the enforcement of these principles often reflect the values and 
      ideologies of those who control the platform.

    </p>
    <p>
      X’s <em>current</em> policies and moderation processes have proven to demonstrate
      highly political and ideological biases, as seen through the posts that have been
      uploaded despite the ‘strict’ moderation process. Posts that involve pejorative
      and discriminatory content, and often ultra right-wing content that deface those
      of opposing views. In many instances, this content seeps through moderation and is
      <i>boosted</i> — meaning increased amplification — and viewed many times before
      getting taken down. In many cases, these posts still prevail and cause like-minded
      individuals to flock and congregate, sharing the same misguided thoughts. Yet, 
      posts that are simply educational or factual — even <i>comedic</i> — are being taken
      down for 'inappropriate' content. This has led to users being <em>censored</em>, 
      <em>unprotected</em> from abuse, and relevant news being taken down. Expression is 
      <em>invalidated</em> by X’s <em>biased moderation</em>, dulling marginalised voices
      while enabling <em>harmful rhetoric</em> to spread, undermining the platform's 
      credibility as a space for open dialogue. 
      
      <br/><br/>
      
      Our project investigates this “grey area” of moderation; how X navigates — or fails
      to navigate — the intersection of protecting users from <i>harm</i> and protecting
      <i>freedom of speech</i>. We explore key areas of the issue through four lenses: 
      opportunities, risks, choices, and the overall impact of content moderation 
      inconsistencies. We have supported our investigation with academic text, journalistic
      sources and reports, and current statistics, all of which inform the insights and 
      recommendations presented in our research. Through this analysis, we aim to foster a
      deeper understanding of digital speech governance and contribute to ongoing discussions
      about the ethics of content moderation.
      
      
    </p>
  </div>

  <div class="figures">
    <img src="https://cdn.glitch.global/5556ebdb-685a-4d04-aa89-e5756f7b1ce6/megaphone.png?v=1748312814060" alt="Megaphones"/>
    <p>
      (<a href="https://unsplash.com/illustrations/a-computer-screen-with-a-bullhorn-on-it-L6-wwbdeESE"
        target="_blank">Image via Roundicons, 2025</a>)
    </p>
  </div>
</div>


      
      <!-- Sign and date the page, it's only polite! -->
      <hr />
      <address>
        Made May 2025<br />
        by Group 4: Sameer Farhan, Kevin Sabdao, Archy Prajapati.
      </address>
    </div>
  </body>
</html>
